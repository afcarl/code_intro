{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Challenge #1\n",
    "\n",
    "Before you do anything, run the code block below. This will setup the functions you'll need to complete the challenge and will download 50 articles from the New York Times homepage for you to work with.\n",
    "\n",
    "Now see if you can get the counts for the words \"trump\" and \"climate\" across all of these articles.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- We've already defined a function that will take an article and give us back its words, `split_into_words`. Take advantage of that.\n",
    "- Remember when we're working with collections of data, e.g. a list of articles, we want to use for loops.\n",
    "- Also notice the pattern we've used a few times in this class, of looping over a list and collecting data into another list.\n",
    "- If you want to dump an entire list (let's say it's called a) into another list (let's say it's called b), you can use extend.\n",
    "\n",
    "### More hints\n",
    "\n",
    "This is how we get the words for a single article:\n",
    "\n",
    "```python\n",
    "words = split_into_words(article)\n",
    "```\n",
    "\n",
    "This is how we loop over a list of articles:\n",
    "\n",
    "```python\n",
    "for article in articles:\n",
    "    # do something here\n",
    "```\n",
    "\n",
    "This is how you add a list to another list:\n",
    "\n",
    "```python\n",
    "list_a = [1,2,3,4]\n",
    "list_b = [5,6,7,8]\n",
    "list_a.extend(list_b)\n",
    "print(list_a)\n",
    "# >>> [1,2,3,4,5,6,7,8]\n",
    "```\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Split each article into its words using the function `split_into_words`\n",
    "2. Combine all these lists of words into one big list of words\n",
    "3. Create a `Counter` with this big list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "requests_cache.install_cache('/tmp/newspaper.cache', backend='sqlite', expire_after=60*60*24*2) # expire after two days\n",
    "\n",
    "import newspaper\n",
    "from collections import Counter\n",
    "\n",
    "def split_into_words(article):\n",
    "    # First, we want to lower case and remove all punctuation from the article text.\n",
    "    # Because we don't want \"Hello!\" to be treated differently from \"hello\".\n",
    "    text = article.text.lower()\n",
    "    text = text.replace('.', ' ')\n",
    "    text = text.replace('!', ' ')\n",
    "    text = text.replace('?', ' ')\n",
    "    text = text.replace(\"'\", ' ')\n",
    "    text = text.replace(\"â€™\", ' ') # this is actually diff from the prev line\n",
    "    text = text.replace('\"', ' ')\n",
    "    text = text.replace(',', ' ')\n",
    "\n",
    "    # Now we can split it into words\n",
    "    return text.split()\n",
    "\n",
    "def download_articles(articles, amount=50):\n",
    "    ok_articles = []\n",
    "    for article in articles[:amount]:\n",
    "        try:\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            ok_articles.append(article)\n",
    "        except newspaper.ArticleException:\n",
    "            pass\n",
    "    return ok_articles\n",
    "\n",
    "# This will grab as many NYT articles as it can from the main page\n",
    "nyt = newspaper.build('https://nytimes.com/', memoize_articles=False)\n",
    "nyt_articles = download_articles(nyt.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Challenge #2\n",
    "\n",
    "Grab the articles from another news site using `newspaper` and get the counts for 'trump' and 'climate' on that page. How do those mentions compare to the NYT?\n",
    "\n",
    "Hint: look to the previous block for how we get the articles for a news site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
